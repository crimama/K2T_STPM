{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm \n",
    "import numpy as np \n",
    "import cv2 \n",
    "from sklearn.metrics import roc_curve, auc \n",
    "import matplotlib.pyplot as plt \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import DataLoader \n",
    "from torchvision import transforms \n",
    "from IPython.display import clear_output\n",
    "\n",
    "from src import Datadir_init,MVtecADDataset\n",
    "from src import ResNet18,get_networks\n",
    "from src import STPM_detection, mkd_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gt(root, cls):\n",
    "    gt = []\n",
    "    gt_dir = os.path.join(root, cls, 'ground_truth')\n",
    "    sub_dirs = sorted(os.listdir(gt_dir))\n",
    "    for sb in sub_dirs:\n",
    "        for fname in sorted(os.listdir(os.path.join(gt_dir, sb))):\n",
    "            temp = cv2.imread(os.path.join(gt_dir, sb, fname), cv2.IMREAD_GRAYSCALE)\n",
    "            temp = cv2.resize(temp, (256, 256)).astype(np.bool)[None, ...]\n",
    "            gt.append(temp)\n",
    "    gt = np.concatenate(gt, 0)\n",
    "    return  gt\n",
    "\n",
    "def preprocess(cfg,augmentation=None):\n",
    "    #mk save dir \n",
    "    try:\n",
    "        os.mkdir(f\"./Save_models/{cfg['class']}\")\n",
    "    except:\n",
    "        pass\n",
    "    #Seed fix \n",
    "    torch.manual_seed(cfg['seed'])\n",
    "    np.random.seed(cfg['seed'])\n",
    "\n",
    "    #Data load \n",
    "    Data_dir = Datadir_init(cfg['root'],cfg['class'])\n",
    "    train_dirs = Data_dir.train_load()\n",
    "    test_dirs,test_labels = Data_dir.test_load()\n",
    "    \n",
    "    gt = load_gt(cfg['root'],cfg['class'])\n",
    "    true_gt = np.zeros((len(test_labels), 256, 256), dtype=np.bool)\n",
    "    true_gt[np.where(test_labels==1)[0]]= gt\n",
    "\n",
    "\n",
    "    indx = int(len(train_dirs)*0.8)\n",
    "    train_dset = MVtecADDataset(cfg,train_dirs[:indx],Augmentation=augmentation)\n",
    "    valid_dset = MVtecADDataset(cfg,train_dirs[indx:])\n",
    "    test_dset = MVtecADDataset(cfg,test_dirs,test_labels)\n",
    "\n",
    "    train_loader = DataLoader(train_dset,batch_size=cfg['batch_size'],shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dset,batch_size=cfg['batch_size'],shuffle=False)\n",
    "    test_loader = DataLoader(test_dset,batch_size=cfg['batch_size'],shuffle=False)\n",
    "    return train_loader,valid_loader,test_loader,true_gt,test_labels \n",
    "\n",
    "class MseDirectionLoss(nn.Module):\n",
    "    def __init__(self, lamda,model):\n",
    "        super(MseDirectionLoss, self).__init__()\n",
    "        self.lamda = lamda\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.similarity_loss = torch.nn.CosineSimilarity()\n",
    "        self.model = model \n",
    "\n",
    "    def forward(self, output_pred, output_real):\n",
    "        \n",
    "        y_pred_0, y_pred_1, y_pred_2, y_pred_3 = output_pred[3], output_pred[6], output_pred[9], output_pred[12]\n",
    "        y_0, y_1, y_2, y_3 = output_real[3], output_real[6], output_real[9], output_real[12]\n",
    "\n",
    "        # different terms of loss\n",
    "        abs_loss_0 = self.criterion(y_pred_0, y_0)\n",
    "        loss_0 = torch.mean(1 - self.similarity_loss(y_pred_0.view(y_pred_0.shape[0], -1), y_0.view(y_0.shape[0], -1)))\n",
    "        abs_loss_1 = self.criterion(y_pred_1, y_1)\n",
    "        loss_1 = torch.mean(1 - self.similarity_loss(y_pred_1.view(y_pred_1.shape[0], -1), y_1.view(y_1.shape[0], -1)))\n",
    "        abs_loss_2 = self.criterion(y_pred_2, y_2)\n",
    "        loss_2 = torch.mean(1 - self.similarity_loss(y_pred_2.view(y_pred_2.shape[0], -1), y_2.view(y_2.shape[0], -1)))\n",
    "        abs_loss_3 = self.criterion(y_pred_3, y_3)\n",
    "        loss_3 = torch.mean(1 - self.similarity_loss(y_pred_3.view(y_pred_3.shape[0], -1), y_3.view(y_3.shape[0], -1)))\n",
    "\n",
    "        total_loss = loss_0 + loss_1 + loss_2 + loss_3 + self.lamda * (\n",
    "                abs_loss_0 + abs_loss_1 + abs_loss_2 + abs_loss_3)\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    \n",
    "def make_transform():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize([256, 256]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(student,teacher,train_loader,criterion,optimizer,cfg):\n",
    "    teacher.eval()\n",
    "    student.train()\n",
    "    train_loss = [] \n",
    "    for batch_imgs,_ in train_loader:\n",
    "        batch_imgs = batch_imgs.to(cfg['device']).type(torch.float32)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            feat_t = teacher(batch_imgs)\n",
    "        feat_s = student(batch_imgs)\n",
    "\n",
    "        loss = criterion(feat_t,feat_s)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "\n",
    "        train_loss.append(loss.detach().cpu().numpy())\n",
    "    return train_loss \n",
    "\n",
    "def valid_epoch(student,teacher,valid_loader,criterion,cfg):\n",
    "    teacher.eval()\n",
    "    student.eval()\n",
    "    valid_loss = [] \n",
    "    for batch_imgs,_ in valid_loader:\n",
    "        batch_imgs = batch_imgs.to(cfg['device']).type(torch.float32)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            feat_t = teacher(batch_imgs)\n",
    "        feat_s = student(batch_imgs)\n",
    "\n",
    "        loss = criterion(feat_t,feat_s)\n",
    "\n",
    "\n",
    "        valid_loss.append(loss.detach().cpu().numpy())\n",
    "    return valid_loss     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {} \n",
    "cfg['img_size']= 128 \n",
    "cfg['class_name'] = 'bottle'\n",
    "cfg['batch_size']= 32 \n",
    "cfg['lr'] = 0.4\n",
    "cfg['Epochs'] = 100 \n",
    "cfg['device'] = 'cuda:0'\n",
    "cfg['seed'] = 0 \n",
    "cfg['root'] = './Dataset'\n",
    "cfg['class'] = 'transistor'\n",
    "cfg['lambda'] = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = cfg['device']\n",
    "#student = ResNet18(Pretrained=False).to(device)\n",
    "#teacher = ResNet18(Pretrained=True).to(device)\n",
    "teacher,student = get_networks()\n",
    "transform = make_transform()\n",
    "train_loader,valid_loader,test_loader,true_gt,test_labels = preprocess(cfg,transform)\n",
    "\n",
    "criterion = MseDirectionLoss(cfg['lambda'],'mkd')\n",
    "optimizer = torch.optim.Adam(student.parameters(),lr=cfg['lr'])\n",
    "#detector = mkd_detection(test_loader,'mkd',cfg)\n",
    "detector = STPM_detection(test_loader,'mkd',cfg)\n",
    "clear_output()\n",
    "\n",
    "\n",
    "total_train_loss = [] \n",
    "total_valid_loss = [] \n",
    "best_valid_loss = np.inf \n",
    "print('Training start')\n",
    "\n",
    "for epoch in tqdm(range(cfg['Epochs'])):\n",
    "    train_loss = train_epoch(student,teacher,train_loader,criterion,optimizer,cfg)\n",
    "    valid_loss = valid_epoch(student,teacher,valid_loader,criterion,cfg)\n",
    "\n",
    "    print(f'\\t epoch : {epoch+1} train loss : {np.mean(train_loss):.3f}')\n",
    "    print(f'\\t epoch : {epoch+1} valid loss : {np.mean(valid_loss):.3f}')\n",
    "\n",
    "    total_train_loss.append(train_loss)\n",
    "    total_valid_loss.append(valid_loss)\n",
    "\n",
    "    \n",
    "    #image_auroc = detector.auroc(teacher,student)\n",
    "    pixel_auroc,image_auroc  = detector.test_inference(teacher,student,test_loader,true_gt,test_labels)\n",
    "    print(f\"\\t Pixel AUROC : {pixel_auroc:.3f}\")\n",
    "    print(f\"\\t Image AUROC : {image_auroc:.3f}\")\n",
    "\n",
    "'''\n",
    "#check point \n",
    "    if valid_loss < best_valid_loss:\n",
    "        torch.save(student,f\"./Save_models/{cfg['class']}/best.pt\")\n",
    "        best_valid_loss = valid_loss \n",
    "        print(f'\\t Model save : {epoch} | best loss : {best_valid_loss :.3f}')\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
